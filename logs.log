2025-06-19 19:45:13,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 19:45:13,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 19:45:13,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 19:45:13,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 19:45:37,199:INFO:PyCaret ClassificationExperiment
2025-06-19 19:45:37,199:INFO:Logging name: clf-default-name
2025-06-19 19:45:37,199:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-19 19:45:37,199:INFO:version 3.3.0
2025-06-19 19:45:37,199:INFO:Initializing setup()
2025-06-19 19:45:37,199:INFO:self.USI: 4ed8
2025-06-19 19:45:37,199:INFO:self._variable_keys: {'y_train', 'fold_groups_param', 'fold_shuffle_param', 'data', 'log_plots_param', 'n_jobs_param', 'X_test', 'idx', 'html_param', 'gpu_param', 'logging_param', 'exp_id', 'pipeline', 'seed', 'y', '_ml_usecase', 'memory', 'X_train', 'target_param', 'fix_imbalance', 'fold_generator', 'USI', 'gpu_n_jobs_param', 'exp_name_log', '_available_plots', 'X', 'y_test', 'is_multiclass'}
2025-06-19 19:45:37,199:INFO:Checking environment
2025-06-19 19:45:37,199:INFO:python_version: 3.10.6
2025-06-19 19:45:37,200:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2025-06-19 19:45:37,200:INFO:machine: AMD64
2025-06-19 19:45:37,223:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-19 19:45:37,229:INFO:Memory: svmem(total=8344559616, available=1058652160, percent=87.3, used=7285907456, free=1058652160)
2025-06-19 19:45:37,229:INFO:Physical Core: 2
2025-06-19 19:45:37,229:INFO:Logical Core: 4
2025-06-19 19:45:37,229:INFO:Checking libraries
2025-06-19 19:45:37,229:INFO:System:
2025-06-19 19:45:37,229:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2025-06-19 19:45:37,229:INFO:executable: C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\python.exe
2025-06-19 19:45:37,229:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-19 19:45:37,230:INFO:PyCaret required dependencies:
2025-06-19 19:45:37,231:INFO:                 pip: 24.3.1
2025-06-19 19:45:37,232:INFO:          setuptools: 69.5.1
2025-06-19 19:45:37,232:INFO:             pycaret: 3.3.0
2025-06-19 19:45:37,232:INFO:             IPython: 8.15.0
2025-06-19 19:45:37,232:INFO:          ipywidgets: 8.1.1
2025-06-19 19:45:37,232:INFO:                tqdm: 4.67.1
2025-06-19 19:45:37,233:INFO:               numpy: 1.26.4
2025-06-19 19:45:37,233:INFO:              pandas: 2.1.4
2025-06-19 19:45:37,233:INFO:              jinja2: 3.1.2
2025-06-19 19:45:37,233:INFO:               scipy: 1.11.4
2025-06-19 19:45:37,233:INFO:              joblib: 1.3.2
2025-06-19 19:45:37,233:INFO:             sklearn: 1.4.1.post1
2025-06-19 19:45:37,233:INFO:                pyod: 2.0.5
2025-06-19 19:45:37,233:INFO:            imblearn: 0.12.0
2025-06-19 19:45:37,233:INFO:   category_encoders: 2.7.0
2025-06-19 19:45:37,233:INFO:            lightgbm: 4.3.0
2025-06-19 19:45:37,233:INFO:               numba: 0.61.2
2025-06-19 19:45:37,233:INFO:            requests: 2.31.0
2025-06-19 19:45:37,233:INFO:          matplotlib: 3.7.2
2025-06-19 19:45:37,233:INFO:          scikitplot: 0.3.7
2025-06-19 19:45:37,233:INFO:         yellowbrick: 1.5
2025-06-19 19:45:37,233:INFO:              plotly: 5.18.0
2025-06-19 19:45:37,233:INFO:    plotly-resampler: Not installed
2025-06-19 19:45:37,234:INFO:             kaleido: 0.2.1
2025-06-19 19:45:37,234:INFO:           schemdraw: 0.15
2025-06-19 19:45:37,234:INFO:         statsmodels: 0.14.4
2025-06-19 19:45:37,234:INFO:              sktime: 0.26.0
2025-06-19 19:45:37,234:INFO:               tbats: 1.1.3
2025-06-19 19:45:37,234:INFO:            pmdarima: 2.0.4
2025-06-19 19:45:37,234:INFO:              psutil: 5.9.8
2025-06-19 19:45:37,234:INFO:          markupsafe: 2.1.3
2025-06-19 19:45:37,234:INFO:             pickle5: Not installed
2025-06-19 19:45:37,234:INFO:         cloudpickle: 3.0.0
2025-06-19 19:45:37,234:INFO:         deprecation: 2.1.0
2025-06-19 19:45:37,234:INFO:              xxhash: 3.5.0
2025-06-19 19:45:37,234:INFO:           wurlitzer: Not installed
2025-06-19 19:45:37,234:INFO:PyCaret optional dependencies:
2025-06-19 19:45:38,230:INFO:                shap: Not installed
2025-06-19 19:45:38,230:INFO:           interpret: Not installed
2025-06-19 19:45:38,230:INFO:                umap: Not installed
2025-06-19 19:45:38,231:INFO:     ydata_profiling: Not installed
2025-06-19 19:45:38,231:INFO:  explainerdashboard: Not installed
2025-06-19 19:45:38,231:INFO:             autoviz: Not installed
2025-06-19 19:45:38,231:INFO:           fairlearn: Not installed
2025-06-19 19:45:38,231:INFO:          deepchecks: Not installed
2025-06-19 19:45:38,231:INFO:             xgboost: 2.0.3
2025-06-19 19:45:38,231:INFO:            catboost: 1.2.8
2025-06-19 19:45:38,231:INFO:              kmodes: Not installed
2025-06-19 19:45:38,231:INFO:             mlxtend: 0.22.0
2025-06-19 19:45:38,231:INFO:       statsforecast: Not installed
2025-06-19 19:45:38,231:INFO:        tune_sklearn: Not installed
2025-06-19 19:45:38,231:INFO:                 ray: Not installed
2025-06-19 19:45:38,231:INFO:            hyperopt: Not installed
2025-06-19 19:45:38,231:INFO:              optuna: Not installed
2025-06-19 19:45:38,231:INFO:               skopt: Not installed
2025-06-19 19:45:38,231:INFO:              mlflow: 2.22.0
2025-06-19 19:45:38,232:INFO:              gradio: Not installed
2025-06-19 19:45:38,232:INFO:             fastapi: 0.111.0
2025-06-19 19:45:38,232:INFO:             uvicorn: 0.29.0
2025-06-19 19:45:38,232:INFO:              m2cgen: Not installed
2025-06-19 19:45:38,232:INFO:           evidently: Not installed
2025-06-19 19:45:38,232:INFO:               fugue: Not installed
2025-06-19 19:45:38,232:INFO:           streamlit: 1.32.0
2025-06-19 19:45:38,232:INFO:             prophet: Not installed
2025-06-19 19:45:38,232:INFO:None
2025-06-19 19:45:38,232:INFO:Set up data.
2025-06-19 19:45:38,267:INFO:Set up folding strategy.
2025-06-19 19:45:38,267:INFO:Set up train/test split.
2025-06-19 19:45:38,412:INFO:Set up index.
2025-06-19 19:45:38,414:INFO:Assigning column types.
2025-06-19 19:45:38,426:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-19 19:45:38,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-19 19:45:38,475:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 19:45:38,519:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:38,522:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:38,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-19 19:45:38,707:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 19:45:38,733:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:38,736:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:38,736:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-19 19:45:38,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 19:45:38,806:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:38,808:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:38,850:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 19:45:38,877:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:38,879:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:38,880:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-19 19:45:38,981:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:38,988:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:39,129:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:39,132:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:39,136:INFO:Preparing preprocessing pipeline...
2025-06-19 19:45:39,139:INFO:Set up simple imputation.
2025-06-19 19:45:39,148:INFO:Set up encoding of ordinal features.
2025-06-19 19:45:39,153:INFO:Set up encoding of categorical features.
2025-06-19 19:45:39,153:INFO:Set up feature selection.
2025-06-19 19:45:39,241:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:39,245:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:40,355:INFO:Finished creating preprocessing pipeline.
2025-06-19 19:45:40,399:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Tayyaba\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              m...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-06-19 19:45:40,399:INFO:Creating final display dataframe.
2025-06-19 19:45:44,607:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       is_promoted
2                   Target type            Binary
3           Original data shape       (43846, 12)
4        Transformed data shape        (43846, 3)
5   Transformed train set shape        (30692, 3)
6    Transformed test set shape        (13154, 3)
7              Numeric features                 6
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15            Feature selection              True
16     Feature selection method           classic
17  Feature selection estimator          lightgbm
18  Number of features selected               0.2
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              4ed8
2025-06-19 19:45:44,714:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:44,718:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:44,818:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 19:45:44,822:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 19:45:44,824:INFO:setup() successfully completed in 7.66s...............
2025-06-19 19:45:44,824:INFO:Initializing compare_models()
2025-06-19 19:45:44,824:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-19 19:45:44,824:INFO:Checking exceptions
2025-06-19 19:45:44,835:INFO:Preparing display monitor
2025-06-19 19:45:44,841:INFO:Initializing Logistic Regression
2025-06-19 19:45:44,842:INFO:Total runtime is 1.4007091522216797e-05 minutes
2025-06-19 19:45:44,842:INFO:SubProcess create_model() called ==================================
2025-06-19 19:45:44,844:INFO:Initializing create_model()
2025-06-19 19:45:44,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:45:44,844:INFO:Checking exceptions
2025-06-19 19:45:44,844:INFO:Importing libraries
2025-06-19 19:45:44,844:INFO:Copying training dataset
2025-06-19 19:45:44,861:INFO:Defining folds
2025-06-19 19:45:44,861:INFO:Declaring metric variables
2025-06-19 19:45:44,862:INFO:Importing untrained model
2025-06-19 19:45:44,862:INFO:Logistic Regression Imported successfully
2025-06-19 19:45:44,862:INFO:Starting cross validation
2025-06-19 19:45:44,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:00,406:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:00,419:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:00,449:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:00,476:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:00,567:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:00,580:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:01,499:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:01,522:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:02,969:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:02,981:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:03,032:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:03,043:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:03,206:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:03,216:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:03,431:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:03,442:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:04,353:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:04,362:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:04,492:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:04,502:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:04,530:INFO:Calculating mean and std
2025-06-19 19:46:04,531:INFO:Creating metrics dataframe
2025-06-19 19:46:04,536:INFO:Uploading results into container
2025-06-19 19:46:04,537:INFO:Uploading model into container now
2025-06-19 19:46:04,538:INFO:_master_model_container: 1
2025-06-19 19:46:04,538:INFO:_display_container: 2
2025-06-19 19:46:04,539:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-19 19:46:04,539:INFO:create_model() successfully completed......................................
2025-06-19 19:46:05,039:INFO:SubProcess create_model() end ==================================
2025-06-19 19:46:05,040:INFO:Creating metrics dataframe
2025-06-19 19:46:05,046:INFO:Initializing K Neighbors Classifier
2025-06-19 19:46:05,046:INFO:Total runtime is 0.3367554068565369 minutes
2025-06-19 19:46:05,047:INFO:SubProcess create_model() called ==================================
2025-06-19 19:46:05,047:INFO:Initializing create_model()
2025-06-19 19:46:05,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:46:05,047:INFO:Checking exceptions
2025-06-19 19:46:05,047:INFO:Importing libraries
2025-06-19 19:46:05,048:INFO:Copying training dataset
2025-06-19 19:46:05,086:INFO:Defining folds
2025-06-19 19:46:05,087:INFO:Declaring metric variables
2025-06-19 19:46:05,088:INFO:Importing untrained model
2025-06-19 19:46:05,088:INFO:K Neighbors Classifier Imported successfully
2025-06-19 19:46:05,089:INFO:Starting cross validation
2025-06-19 19:46:05,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:08,449:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:08,456:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:08,501:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:08,811:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:10,786:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:10,797:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:10,825:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:11,306:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:12,518:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:12,527:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:12,557:INFO:Calculating mean and std
2025-06-19 19:46:12,558:INFO:Creating metrics dataframe
2025-06-19 19:46:12,561:INFO:Uploading results into container
2025-06-19 19:46:12,561:INFO:Uploading model into container now
2025-06-19 19:46:12,562:INFO:_master_model_container: 2
2025-06-19 19:46:12,562:INFO:_display_container: 2
2025-06-19 19:46:12,562:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 19:46:12,562:INFO:create_model() successfully completed......................................
2025-06-19 19:46:12,716:INFO:SubProcess create_model() end ==================================
2025-06-19 19:46:12,716:INFO:Creating metrics dataframe
2025-06-19 19:46:12,719:INFO:Initializing Naive Bayes
2025-06-19 19:46:12,719:INFO:Total runtime is 0.4646419604619344 minutes
2025-06-19 19:46:12,720:INFO:SubProcess create_model() called ==================================
2025-06-19 19:46:12,720:INFO:Initializing create_model()
2025-06-19 19:46:12,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:46:12,720:INFO:Checking exceptions
2025-06-19 19:46:12,720:INFO:Importing libraries
2025-06-19 19:46:12,720:INFO:Copying training dataset
2025-06-19 19:46:12,746:INFO:Defining folds
2025-06-19 19:46:12,746:INFO:Declaring metric variables
2025-06-19 19:46:12,747:INFO:Importing untrained model
2025-06-19 19:46:12,747:INFO:Naive Bayes Imported successfully
2025-06-19 19:46:12,747:INFO:Starting cross validation
2025-06-19 19:46:12,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:14,904:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:14,914:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:14,918:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:14,928:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:15,169:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:15,181:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:15,210:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:15,224:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:17,750:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:17,754:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:17,771:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:17,776:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:17,895:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:17,938:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:21,593:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:21,624:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:22,749:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:22,762:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:22,777:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:22,788:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:22,810:INFO:Calculating mean and std
2025-06-19 19:46:22,811:INFO:Creating metrics dataframe
2025-06-19 19:46:22,817:INFO:Uploading results into container
2025-06-19 19:46:22,818:INFO:Uploading model into container now
2025-06-19 19:46:22,820:INFO:_master_model_container: 3
2025-06-19 19:46:22,820:INFO:_display_container: 2
2025-06-19 19:46:22,820:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-19 19:46:22,820:INFO:create_model() successfully completed......................................
2025-06-19 19:46:23,015:INFO:SubProcess create_model() end ==================================
2025-06-19 19:46:23,015:INFO:Creating metrics dataframe
2025-06-19 19:46:23,022:INFO:Initializing Decision Tree Classifier
2025-06-19 19:46:23,022:INFO:Total runtime is 0.6363603075345357 minutes
2025-06-19 19:46:23,022:INFO:SubProcess create_model() called ==================================
2025-06-19 19:46:23,023:INFO:Initializing create_model()
2025-06-19 19:46:23,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:46:23,023:INFO:Checking exceptions
2025-06-19 19:46:23,023:INFO:Importing libraries
2025-06-19 19:46:23,023:INFO:Copying training dataset
2025-06-19 19:46:23,060:INFO:Defining folds
2025-06-19 19:46:23,061:INFO:Declaring metric variables
2025-06-19 19:46:23,061:INFO:Importing untrained model
2025-06-19 19:46:23,062:INFO:Decision Tree Classifier Imported successfully
2025-06-19 19:46:23,063:INFO:Starting cross validation
2025-06-19 19:46:23,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:25,318:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:25,319:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:25,342:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:25,985:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:27,752:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:27,792:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:27,825:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:28,089:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:29,008:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:29,086:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:29,129:INFO:Calculating mean and std
2025-06-19 19:46:29,131:INFO:Creating metrics dataframe
2025-06-19 19:46:29,136:INFO:Uploading results into container
2025-06-19 19:46:29,137:INFO:Uploading model into container now
2025-06-19 19:46:29,138:INFO:_master_model_container: 4
2025-06-19 19:46:29,139:INFO:_display_container: 2
2025-06-19 19:46:29,140:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-19 19:46:29,140:INFO:create_model() successfully completed......................................
2025-06-19 19:46:29,331:INFO:SubProcess create_model() end ==================================
2025-06-19 19:46:29,331:INFO:Creating metrics dataframe
2025-06-19 19:46:29,335:INFO:Initializing SVM - Linear Kernel
2025-06-19 19:46:29,335:INFO:Total runtime is 0.74157262245814 minutes
2025-06-19 19:46:29,336:INFO:SubProcess create_model() called ==================================
2025-06-19 19:46:29,336:INFO:Initializing create_model()
2025-06-19 19:46:29,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:46:29,336:INFO:Checking exceptions
2025-06-19 19:46:29,336:INFO:Importing libraries
2025-06-19 19:46:29,336:INFO:Copying training dataset
2025-06-19 19:46:29,368:INFO:Defining folds
2025-06-19 19:46:29,368:INFO:Declaring metric variables
2025-06-19 19:46:29,368:INFO:Importing untrained model
2025-06-19 19:46:29,369:INFO:SVM - Linear Kernel Imported successfully
2025-06-19 19:46:29,369:INFO:Starting cross validation
2025-06-19 19:46:29,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:33,625:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:33,625:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:33,633:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:33,640:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:33,643:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:33,648:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:34,191:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:34,205:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:35,523:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:35,531:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:35,537:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:35,543:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:35,545:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:35,559:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:36,412:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:36,426:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:37,864:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:37,875:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:37,922:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:37,931:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:37,958:INFO:Calculating mean and std
2025-06-19 19:46:37,959:INFO:Creating metrics dataframe
2025-06-19 19:46:37,963:INFO:Uploading results into container
2025-06-19 19:46:37,964:INFO:Uploading model into container now
2025-06-19 19:46:37,964:INFO:_master_model_container: 5
2025-06-19 19:46:37,964:INFO:_display_container: 2
2025-06-19 19:46:37,969:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-19 19:46:37,969:INFO:create_model() successfully completed......................................
2025-06-19 19:46:38,188:INFO:SubProcess create_model() end ==================================
2025-06-19 19:46:38,189:INFO:Creating metrics dataframe
2025-06-19 19:46:38,194:INFO:Initializing Ridge Classifier
2025-06-19 19:46:38,194:INFO:Total runtime is 0.8892224589983622 minutes
2025-06-19 19:46:38,195:INFO:SubProcess create_model() called ==================================
2025-06-19 19:46:38,195:INFO:Initializing create_model()
2025-06-19 19:46:38,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:46:38,195:INFO:Checking exceptions
2025-06-19 19:46:38,195:INFO:Importing libraries
2025-06-19 19:46:38,195:INFO:Copying training dataset
2025-06-19 19:46:38,233:INFO:Defining folds
2025-06-19 19:46:38,233:INFO:Declaring metric variables
2025-06-19 19:46:38,234:INFO:Importing untrained model
2025-06-19 19:46:38,235:INFO:Ridge Classifier Imported successfully
2025-06-19 19:46:38,235:INFO:Starting cross validation
2025-06-19 19:46:38,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:40,521:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:40,523:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:40,535:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:40,536:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:40,678:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:40,690:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:40,701:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:40,714:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:43,090:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:43,100:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:43,103:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:43,112:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:43,308:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:43,318:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:43,332:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:43,343:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:45,698:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:45,700:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 19:46:45,712:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:45,716:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:46:45,756:INFO:Calculating mean and std
2025-06-19 19:46:45,759:INFO:Creating metrics dataframe
2025-06-19 19:46:45,762:INFO:Uploading results into container
2025-06-19 19:46:45,763:INFO:Uploading model into container now
2025-06-19 19:46:45,763:INFO:_master_model_container: 6
2025-06-19 19:46:45,764:INFO:_display_container: 2
2025-06-19 19:46:45,765:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-19 19:46:45,765:INFO:create_model() successfully completed......................................
2025-06-19 19:46:45,924:INFO:SubProcess create_model() end ==================================
2025-06-19 19:46:45,924:INFO:Creating metrics dataframe
2025-06-19 19:46:45,928:INFO:Initializing Random Forest Classifier
2025-06-19 19:46:45,928:INFO:Total runtime is 1.0181208848953247 minutes
2025-06-19 19:46:45,928:INFO:SubProcess create_model() called ==================================
2025-06-19 19:46:45,929:INFO:Initializing create_model()
2025-06-19 19:46:45,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:46:45,929:INFO:Checking exceptions
2025-06-19 19:46:45,929:INFO:Importing libraries
2025-06-19 19:46:45,929:INFO:Copying training dataset
2025-06-19 19:46:45,957:INFO:Defining folds
2025-06-19 19:46:45,958:INFO:Declaring metric variables
2025-06-19 19:46:45,958:INFO:Importing untrained model
2025-06-19 19:46:45,959:INFO:Random Forest Classifier Imported successfully
2025-06-19 19:46:45,960:INFO:Starting cross validation
2025-06-19 19:46:45,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:46:51,558:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:51,568:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:55,320:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:55,413:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:59,401:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:46:59,443:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:01,006:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:02,069:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:03,989:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:04,066:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:04,091:INFO:Calculating mean and std
2025-06-19 19:47:04,093:INFO:Creating metrics dataframe
2025-06-19 19:47:04,102:INFO:Uploading results into container
2025-06-19 19:47:04,103:INFO:Uploading model into container now
2025-06-19 19:47:04,104:INFO:_master_model_container: 7
2025-06-19 19:47:04,104:INFO:_display_container: 2
2025-06-19 19:47:04,105:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-19 19:47:04,105:INFO:create_model() successfully completed......................................
2025-06-19 19:47:04,298:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:04,298:INFO:Creating metrics dataframe
2025-06-19 19:47:04,302:INFO:Initializing Quadratic Discriminant Analysis
2025-06-19 19:47:04,302:INFO:Total runtime is 1.3243603030840556 minutes
2025-06-19 19:47:04,303:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:04,303:INFO:Initializing create_model()
2025-06-19 19:47:04,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:04,304:INFO:Checking exceptions
2025-06-19 19:47:04,304:INFO:Importing libraries
2025-06-19 19:47:04,304:INFO:Copying training dataset
2025-06-19 19:47:04,333:INFO:Defining folds
2025-06-19 19:47:04,334:INFO:Declaring metric variables
2025-06-19 19:47:04,334:INFO:Importing untrained model
2025-06-19 19:47:04,334:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-19 19:47:04,335:INFO:Starting cross validation
2025-06-19 19:47:04,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:06,284:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:06,301:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:06,302:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:06,302:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:06,313:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:06,337:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:06,657:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:06,672:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:08,025:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:08,035:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:08,036:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:08,045:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:08,186:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:08,197:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:08,469:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:08,483:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:09,205:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:09,207:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:09,215:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:09,217:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:09,240:INFO:Calculating mean and std
2025-06-19 19:47:09,242:INFO:Creating metrics dataframe
2025-06-19 19:47:09,246:INFO:Uploading results into container
2025-06-19 19:47:09,247:INFO:Uploading model into container now
2025-06-19 19:47:09,248:INFO:_master_model_container: 8
2025-06-19 19:47:09,249:INFO:_display_container: 2
2025-06-19 19:47:09,249:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-19 19:47:09,249:INFO:create_model() successfully completed......................................
2025-06-19 19:47:09,422:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:09,422:INFO:Creating metrics dataframe
2025-06-19 19:47:09,427:INFO:Initializing Ada Boost Classifier
2025-06-19 19:47:09,427:INFO:Total runtime is 1.4097649137179058 minutes
2025-06-19 19:47:09,427:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:09,427:INFO:Initializing create_model()
2025-06-19 19:47:09,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:09,428:INFO:Checking exceptions
2025-06-19 19:47:09,428:INFO:Importing libraries
2025-06-19 19:47:09,428:INFO:Copying training dataset
2025-06-19 19:47:09,458:INFO:Defining folds
2025-06-19 19:47:09,459:INFO:Declaring metric variables
2025-06-19 19:47:09,459:INFO:Importing untrained model
2025-06-19 19:47:09,460:INFO:Ada Boost Classifier Imported successfully
2025-06-19 19:47:09,460:INFO:Starting cross validation
2025-06-19 19:47:09,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:11,090:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:11,092:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:11,131:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:11,166:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:12,212:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:12,217:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:12,263:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:12,270:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:13,670:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:13,679:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:13,712:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:13,878:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:14,802:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:14,804:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:14,825:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:15,012:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:15,959:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:16,031:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 19:47:17,078:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:17,175:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:17,203:INFO:Calculating mean and std
2025-06-19 19:47:17,204:INFO:Creating metrics dataframe
2025-06-19 19:47:17,209:INFO:Uploading results into container
2025-06-19 19:47:17,210:INFO:Uploading model into container now
2025-06-19 19:47:17,211:INFO:_master_model_container: 9
2025-06-19 19:47:17,211:INFO:_display_container: 2
2025-06-19 19:47:17,211:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-19 19:47:17,211:INFO:create_model() successfully completed......................................
2025-06-19 19:47:17,467:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:17,467:INFO:Creating metrics dataframe
2025-06-19 19:47:17,472:INFO:Initializing Gradient Boosting Classifier
2025-06-19 19:47:17,473:INFO:Total runtime is 1.5438690543174745 minutes
2025-06-19 19:47:17,473:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:17,473:INFO:Initializing create_model()
2025-06-19 19:47:17,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:17,474:INFO:Checking exceptions
2025-06-19 19:47:17,474:INFO:Importing libraries
2025-06-19 19:47:17,474:INFO:Copying training dataset
2025-06-19 19:47:17,541:INFO:Defining folds
2025-06-19 19:47:17,542:INFO:Declaring metric variables
2025-06-19 19:47:17,543:INFO:Importing untrained model
2025-06-19 19:47:17,543:INFO:Gradient Boosting Classifier Imported successfully
2025-06-19 19:47:17,544:INFO:Starting cross validation
2025-06-19 19:47:17,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:21,407:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:21,410:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:21,470:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:21,570:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:24,968:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:24,997:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:25,033:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:25,128:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:27,683:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:27,685:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:27,726:INFO:Calculating mean and std
2025-06-19 19:47:27,728:INFO:Creating metrics dataframe
2025-06-19 19:47:27,732:INFO:Uploading results into container
2025-06-19 19:47:27,732:INFO:Uploading model into container now
2025-06-19 19:47:27,733:INFO:_master_model_container: 10
2025-06-19 19:47:27,733:INFO:_display_container: 2
2025-06-19 19:47:27,733:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-19 19:47:27,734:INFO:create_model() successfully completed......................................
2025-06-19 19:47:27,906:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:27,906:INFO:Creating metrics dataframe
2025-06-19 19:47:27,914:INFO:Initializing Linear Discriminant Analysis
2025-06-19 19:47:27,915:INFO:Total runtime is 1.717912487188975 minutes
2025-06-19 19:47:27,917:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:27,917:INFO:Initializing create_model()
2025-06-19 19:47:27,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:27,918:INFO:Checking exceptions
2025-06-19 19:47:27,918:INFO:Importing libraries
2025-06-19 19:47:27,918:INFO:Copying training dataset
2025-06-19 19:47:27,942:INFO:Defining folds
2025-06-19 19:47:27,943:INFO:Declaring metric variables
2025-06-19 19:47:27,943:INFO:Importing untrained model
2025-06-19 19:47:27,944:INFO:Linear Discriminant Analysis Imported successfully
2025-06-19 19:47:27,944:INFO:Starting cross validation
2025-06-19 19:47:27,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:29,665:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:29,669:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:29,679:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:29,681:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:29,684:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:29,686:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:29,699:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:29,700:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:32,022:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:32,031:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:32,049:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:32,059:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:32,090:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:32,101:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:32,443:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:32,453:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:33,354:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:33,359:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:33,365:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:33,370:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:47:33,400:INFO:Calculating mean and std
2025-06-19 19:47:33,401:INFO:Creating metrics dataframe
2025-06-19 19:47:33,405:INFO:Uploading results into container
2025-06-19 19:47:33,406:INFO:Uploading model into container now
2025-06-19 19:47:33,407:INFO:_master_model_container: 11
2025-06-19 19:47:33,407:INFO:_display_container: 2
2025-06-19 19:47:33,408:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-19 19:47:33,408:INFO:create_model() successfully completed......................................
2025-06-19 19:47:33,557:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:33,557:INFO:Creating metrics dataframe
2025-06-19 19:47:33,560:INFO:Initializing Extra Trees Classifier
2025-06-19 19:47:33,561:INFO:Total runtime is 1.8120046416918436 minutes
2025-06-19 19:47:33,561:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:33,561:INFO:Initializing create_model()
2025-06-19 19:47:33,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:33,562:INFO:Checking exceptions
2025-06-19 19:47:33,562:INFO:Importing libraries
2025-06-19 19:47:33,562:INFO:Copying training dataset
2025-06-19 19:47:33,585:INFO:Defining folds
2025-06-19 19:47:33,585:INFO:Declaring metric variables
2025-06-19 19:47:33,586:INFO:Importing untrained model
2025-06-19 19:47:33,586:INFO:Extra Trees Classifier Imported successfully
2025-06-19 19:47:33,586:INFO:Starting cross validation
2025-06-19 19:47:33,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:36,994:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:37,085:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:37,102:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:38,312:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:40,861:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:40,907:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:40,999:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:42,293:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:43,878:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:43,956:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:43,998:INFO:Calculating mean and std
2025-06-19 19:47:43,999:INFO:Creating metrics dataframe
2025-06-19 19:47:44,004:INFO:Uploading results into container
2025-06-19 19:47:44,005:INFO:Uploading model into container now
2025-06-19 19:47:44,005:INFO:_master_model_container: 12
2025-06-19 19:47:44,005:INFO:_display_container: 2
2025-06-19 19:47:44,007:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-19 19:47:44,007:INFO:create_model() successfully completed......................................
2025-06-19 19:47:44,173:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:44,173:INFO:Creating metrics dataframe
2025-06-19 19:47:44,178:INFO:Initializing Extreme Gradient Boosting
2025-06-19 19:47:44,178:INFO:Total runtime is 1.988956065972646 minutes
2025-06-19 19:47:44,179:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:44,179:INFO:Initializing create_model()
2025-06-19 19:47:44,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:44,179:INFO:Checking exceptions
2025-06-19 19:47:44,179:INFO:Importing libraries
2025-06-19 19:47:44,179:INFO:Copying training dataset
2025-06-19 19:47:44,206:INFO:Defining folds
2025-06-19 19:47:44,207:INFO:Declaring metric variables
2025-06-19 19:47:44,207:INFO:Importing untrained model
2025-06-19 19:47:44,208:INFO:Extreme Gradient Boosting Imported successfully
2025-06-19 19:47:44,209:INFO:Starting cross validation
2025-06-19 19:47:44,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:46,284:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:46,286:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:46,324:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:46,818:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:48,262:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:48,406:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:48,433:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:48,671:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:49,809:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:50,021:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:50,051:INFO:Calculating mean and std
2025-06-19 19:47:50,052:INFO:Creating metrics dataframe
2025-06-19 19:47:50,056:INFO:Uploading results into container
2025-06-19 19:47:50,056:INFO:Uploading model into container now
2025-06-19 19:47:50,057:INFO:_master_model_container: 13
2025-06-19 19:47:50,057:INFO:_display_container: 2
2025-06-19 19:47:50,059:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-06-19 19:47:50,059:INFO:create_model() successfully completed......................................
2025-06-19 19:47:50,207:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:50,207:INFO:Creating metrics dataframe
2025-06-19 19:47:50,211:INFO:Initializing Light Gradient Boosting Machine
2025-06-19 19:47:50,211:INFO:Total runtime is 2.089499847094218 minutes
2025-06-19 19:47:50,211:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:50,212:INFO:Initializing create_model()
2025-06-19 19:47:50,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:50,212:INFO:Checking exceptions
2025-06-19 19:47:50,212:INFO:Importing libraries
2025-06-19 19:47:50,212:INFO:Copying training dataset
2025-06-19 19:47:50,239:INFO:Defining folds
2025-06-19 19:47:50,239:INFO:Declaring metric variables
2025-06-19 19:47:50,239:INFO:Importing untrained model
2025-06-19 19:47:50,240:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-19 19:47:50,240:INFO:Starting cross validation
2025-06-19 19:47:50,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:47:52,581:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:52,583:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:52,697:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:53,034:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:54,742:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:55,226:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:55,278:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:55,527:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:56,446:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:56,701:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:47:56,738:INFO:Calculating mean and std
2025-06-19 19:47:56,739:INFO:Creating metrics dataframe
2025-06-19 19:47:56,743:INFO:Uploading results into container
2025-06-19 19:47:56,744:INFO:Uploading model into container now
2025-06-19 19:47:56,744:INFO:_master_model_container: 14
2025-06-19 19:47:56,744:INFO:_display_container: 2
2025-06-19 19:47:56,745:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-19 19:47:56,745:INFO:create_model() successfully completed......................................
2025-06-19 19:47:56,897:INFO:SubProcess create_model() end ==================================
2025-06-19 19:47:56,897:INFO:Creating metrics dataframe
2025-06-19 19:47:56,901:INFO:Initializing CatBoost Classifier
2025-06-19 19:47:56,901:INFO:Total runtime is 2.2009981632232667 minutes
2025-06-19 19:47:56,901:INFO:SubProcess create_model() called ==================================
2025-06-19 19:47:56,901:INFO:Initializing create_model()
2025-06-19 19:47:56,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:47:56,902:INFO:Checking exceptions
2025-06-19 19:47:56,902:INFO:Importing libraries
2025-06-19 19:47:56,902:INFO:Copying training dataset
2025-06-19 19:47:56,923:INFO:Defining folds
2025-06-19 19:47:56,923:INFO:Declaring metric variables
2025-06-19 19:47:56,924:INFO:Importing untrained model
2025-06-19 19:47:56,932:INFO:CatBoost Classifier Imported successfully
2025-06-19 19:47:56,932:INFO:Starting cross validation
2025-06-19 19:47:56,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:48:36,834:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:48:36,835:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:48:36,863:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:48:36,989:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:13,828:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:13,877:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:13,914:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:15,512:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:43,112:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:43,228:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:43,284:INFO:Calculating mean and std
2025-06-19 19:49:43,294:INFO:Creating metrics dataframe
2025-06-19 19:49:43,333:INFO:Uploading results into container
2025-06-19 19:49:43,335:INFO:Uploading model into container now
2025-06-19 19:49:43,341:INFO:_master_model_container: 15
2025-06-19 19:49:43,342:INFO:_display_container: 2
2025-06-19 19:49:43,343:INFO:<catboost.core.CatBoostClassifier object at 0x000002539604B220>
2025-06-19 19:49:43,343:INFO:create_model() successfully completed......................................
2025-06-19 19:49:44,245:INFO:SubProcess create_model() end ==================================
2025-06-19 19:49:44,246:INFO:Creating metrics dataframe
2025-06-19 19:49:44,258:INFO:Initializing Dummy Classifier
2025-06-19 19:49:44,258:INFO:Total runtime is 3.9902807672818503 minutes
2025-06-19 19:49:44,258:INFO:SubProcess create_model() called ==================================
2025-06-19 19:49:44,259:INFO:Initializing create_model()
2025-06-19 19:49:44,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025396AE0910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:49:44,259:INFO:Checking exceptions
2025-06-19 19:49:44,259:INFO:Importing libraries
2025-06-19 19:49:44,260:INFO:Copying training dataset
2025-06-19 19:49:44,311:INFO:Defining folds
2025-06-19 19:49:44,311:INFO:Declaring metric variables
2025-06-19 19:49:44,312:INFO:Importing untrained model
2025-06-19 19:49:44,313:INFO:Dummy Classifier Imported successfully
2025-06-19 19:49:44,314:INFO:Starting cross validation
2025-06-19 19:49:44,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:49:50,213:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:50,214:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:50,224:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:50,227:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:50,448:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:50,463:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:52,614:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:52,632:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:54,047:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:54,047:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:54,057:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:54,058:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:54,173:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:54,185:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:55,732:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:55,748:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:56,907:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:56,919:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:57,009:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:49:57,021:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-19 19:49:57,051:INFO:Calculating mean and std
2025-06-19 19:49:57,054:INFO:Creating metrics dataframe
2025-06-19 19:49:57,060:INFO:Uploading results into container
2025-06-19 19:49:57,062:INFO:Uploading model into container now
2025-06-19 19:49:57,062:INFO:_master_model_container: 16
2025-06-19 19:49:57,063:INFO:_display_container: 2
2025-06-19 19:49:57,063:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-19 19:49:57,063:INFO:create_model() successfully completed......................................
2025-06-19 19:49:57,379:INFO:SubProcess create_model() end ==================================
2025-06-19 19:49:57,379:INFO:Creating metrics dataframe
2025-06-19 19:49:57,394:INFO:Initializing create_model()
2025-06-19 19:49:57,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:49:57,394:INFO:Checking exceptions
2025-06-19 19:49:57,397:INFO:Importing libraries
2025-06-19 19:49:57,398:INFO:Copying training dataset
2025-06-19 19:49:57,444:INFO:Defining folds
2025-06-19 19:49:57,445:INFO:Declaring metric variables
2025-06-19 19:49:57,445:INFO:Importing untrained model
2025-06-19 19:49:57,445:INFO:Declaring custom model
2025-06-19 19:49:57,447:INFO:K Neighbors Classifier Imported successfully
2025-06-19 19:49:57,473:INFO:Cross validation set to False
2025-06-19 19:49:57,473:INFO:Fitting Model
2025-06-19 19:49:58,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-19 19:49:58,424:INFO:[LightGBM] [Info] Number of positive: 2614, number of negative: 28078
2025-06-19 19:49:58,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008931 seconds.
2025-06-19 19:49:58,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-19 19:49:58,437:INFO:[LightGBM] [Info] Total Bins 223
2025-06-19 19:49:58,438:INFO:[LightGBM] [Info] Number of data points in the train set: 30692, number of used features: 23
2025-06-19 19:49:58,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.085169 -> initscore=-2.374105
2025-06-19 19:49:58,439:INFO:[LightGBM] [Info] Start training from score -2.374105
2025-06-19 19:49:59,433:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 19:49:59,434:INFO:create_model() successfully completed......................................
2025-06-19 19:50:01,070:INFO:_master_model_container: 16
2025-06-19 19:50:01,071:INFO:_display_container: 2
2025-06-19 19:50:01,071:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 19:50:01,071:INFO:compare_models() successfully completed......................................
2025-06-19 19:50:01,967:INFO:Initializing tune_model()
2025-06-19 19:50:01,967:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>)
2025-06-19 19:50:01,967:INFO:Checking exceptions
2025-06-19 19:50:01,992:INFO:Copying training dataset
2025-06-19 19:50:02,023:INFO:Checking base model
2025-06-19 19:50:02,024:INFO:Base model : K Neighbors Classifier
2025-06-19 19:50:02,025:INFO:Declaring metric variables
2025-06-19 19:50:02,026:INFO:Defining Hyperparameters
2025-06-19 19:50:02,461:INFO:Tuning with n_jobs=-1
2025-06-19 19:50:02,463:INFO:Initializing RandomizedSearchCV
2025-06-19 19:51:33,657:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 11, 'actual_estimator__metric': 'minkowski'}
2025-06-19 19:51:33,658:INFO:Hyperparameter search completed
2025-06-19 19:51:33,658:INFO:SubProcess create_model() called ==================================
2025-06-19 19:51:33,659:INFO:Initializing create_model()
2025-06-19 19:51:33,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002539604BD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'weights': 'uniform', 'n_neighbors': 11, 'metric': 'minkowski'})
2025-06-19 19:51:33,660:INFO:Checking exceptions
2025-06-19 19:51:33,660:INFO:Importing libraries
2025-06-19 19:51:33,660:INFO:Copying training dataset
2025-06-19 19:51:33,698:INFO:Defining folds
2025-06-19 19:51:33,698:INFO:Declaring metric variables
2025-06-19 19:51:33,700:INFO:Importing untrained model
2025-06-19 19:51:33,700:INFO:Declaring custom model
2025-06-19 19:51:33,704:INFO:K Neighbors Classifier Imported successfully
2025-06-19 19:51:33,705:INFO:Starting cross validation
2025-06-19 19:51:33,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:51:38,372:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:38,392:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:38,451:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:38,715:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:40,849:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:40,856:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:41,263:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:43,605:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:43,626:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:43,676:INFO:Calculating mean and std
2025-06-19 19:51:43,677:INFO:Creating metrics dataframe
2025-06-19 19:51:43,687:INFO:Finalizing model
2025-06-19 19:51:44,786:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-19 19:51:44,788:INFO:[LightGBM] [Info] Number of positive: 2614, number of negative: 28078
2025-06-19 19:51:44,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004748 seconds.
2025-06-19 19:51:44,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-19 19:51:44,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-19 19:51:44,808:INFO:[LightGBM] [Info] Total Bins 223
2025-06-19 19:51:44,809:INFO:[LightGBM] [Info] Number of data points in the train set: 30692, number of used features: 23
2025-06-19 19:51:44,809:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.085169 -> initscore=-2.374105
2025-06-19 19:51:44,809:INFO:[LightGBM] [Info] Start training from score -2.374105
2025-06-19 19:51:45,836:INFO:Uploading results into container
2025-06-19 19:51:45,837:INFO:Uploading model into container now
2025-06-19 19:51:45,839:INFO:_master_model_container: 17
2025-06-19 19:51:45,839:INFO:_display_container: 3
2025-06-19 19:51:45,839:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=11, p=2,
                     weights='uniform')
2025-06-19 19:51:45,839:INFO:create_model() successfully completed......................................
2025-06-19 19:51:46,419:INFO:SubProcess create_model() end ==================================
2025-06-19 19:51:46,419:INFO:choose_better activated
2025-06-19 19:51:46,420:INFO:SubProcess create_model() called ==================================
2025-06-19 19:51:46,421:INFO:Initializing create_model()
2025-06-19 19:51:46,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:51:46,421:INFO:Checking exceptions
2025-06-19 19:51:46,423:INFO:Importing libraries
2025-06-19 19:51:46,423:INFO:Copying training dataset
2025-06-19 19:51:46,485:INFO:Defining folds
2025-06-19 19:51:46,486:INFO:Declaring metric variables
2025-06-19 19:51:46,486:INFO:Importing untrained model
2025-06-19 19:51:46,486:INFO:Declaring custom model
2025-06-19 19:51:46,487:INFO:K Neighbors Classifier Imported successfully
2025-06-19 19:51:46,488:INFO:Starting cross validation
2025-06-19 19:51:46,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 19:51:50,457:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:50,524:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:50,525:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:51,284:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:53,591:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:53,643:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:53,690:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:54,787:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:56,485:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:56,497:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['no_of_trainings', 'previous_year_rating', 'length_of_service', 'awards_won'] not in index"

  warnings.warn(

2025-06-19 19:51:56,533:INFO:Calculating mean and std
2025-06-19 19:51:56,534:INFO:Creating metrics dataframe
2025-06-19 19:51:56,539:INFO:Finalizing model
2025-06-19 19:51:57,257:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-19 19:51:57,259:INFO:[LightGBM] [Info] Number of positive: 2614, number of negative: 28078
2025-06-19 19:51:57,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004604 seconds.
2025-06-19 19:51:57,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-19 19:51:57,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-19 19:51:57,272:INFO:[LightGBM] [Info] Total Bins 223
2025-06-19 19:51:57,272:INFO:[LightGBM] [Info] Number of data points in the train set: 30692, number of used features: 23
2025-06-19 19:51:57,272:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.085169 -> initscore=-2.374105
2025-06-19 19:51:57,273:INFO:[LightGBM] [Info] Start training from score -2.374105
2025-06-19 19:51:58,124:INFO:Uploading results into container
2025-06-19 19:51:58,125:INFO:Uploading model into container now
2025-06-19 19:51:58,126:INFO:_master_model_container: 18
2025-06-19 19:51:58,126:INFO:_display_container: 4
2025-06-19 19:51:58,127:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 19:51:58,127:INFO:create_model() successfully completed......................................
2025-06-19 19:51:58,333:INFO:SubProcess create_model() end ==================================
2025-06-19 19:51:58,334:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for F1 is 0.2075
2025-06-19 19:51:58,335:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=11, p=2,
                     weights='uniform') result for F1 is 0.2004
2025-06-19 19:51:58,336:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') is best model
2025-06-19 19:51:58,336:INFO:choose_better completed
2025-06-19 19:51:58,336:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-19 19:51:58,337:INFO:_master_model_container: 18
2025-06-19 19:51:58,337:INFO:_display_container: 3
2025-06-19 19:51:58,338:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 19:51:58,338:INFO:tune_model() successfully completed......................................
2025-06-19 19:51:58,521:INFO:Initializing finalize_model()
2025-06-19 19:51:58,521:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-19 19:51:58,522:INFO:Finalizing KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 19:51:58,541:INFO:Initializing create_model()
2025-06-19 19:51:58,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 19:51:58,541:INFO:Checking exceptions
2025-06-19 19:51:58,543:INFO:Importing libraries
2025-06-19 19:51:58,544:INFO:Copying training dataset
2025-06-19 19:51:58,551:INFO:Defining folds
2025-06-19 19:51:58,551:INFO:Declaring metric variables
2025-06-19 19:51:58,552:INFO:Importing untrained model
2025-06-19 19:51:58,552:INFO:Declaring custom model
2025-06-19 19:51:58,553:INFO:K Neighbors Classifier Imported successfully
2025-06-19 19:51:58,588:INFO:Cross validation set to False
2025-06-19 19:51:58,588:INFO:Fitting Model
2025-06-19 19:51:59,614:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-19 19:51:59,616:INFO:[LightGBM] [Info] Number of positive: 3734, number of negative: 40112
2025-06-19 19:51:59,629:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005668 seconds.
2025-06-19 19:51:59,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-19 19:51:59,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-19 19:51:59,630:INFO:[LightGBM] [Info] Total Bins 224
2025-06-19 19:51:59,631:INFO:[LightGBM] [Info] Number of data points in the train set: 43846, number of used features: 23
2025-06-19 19:51:59,632:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.085162 -> initscore=-2.374195
2025-06-19 19:51:59,633:INFO:[LightGBM] [Info] Start training from score -2.374195
2025-06-19 19:52:00,873:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2025-06-19 19:52:00,874:INFO:create_model() successfully completed......................................
2025-06-19 19:52:01,085:INFO:_master_model_container: 18
2025-06-19 19:52:01,085:INFO:_display_container: 3
2025-06-19 19:52:01,148:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2025-06-19 19:52:01,148:INFO:finalize_model() successfully completed......................................
2025-06-19 19:52:01,570:INFO:Initializing predict_model()
2025-06-19 19:52:01,570:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025396197460>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000253967D4160>)
2025-06-19 19:52:01,576:INFO:Checking exceptions
2025-06-19 19:52:01,577:INFO:Preloading libraries
2025-06-19 19:52:01,584:INFO:Set up data.
2025-06-19 19:52:01,624:INFO:Set up index.
2025-06-19 19:52:03,675:INFO:Initializing save_model()
2025-06-19 19:52:03,676:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), model_name=automl_models\pycaret_pycaret_kneighborsclassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Tayyaba\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              m...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-19 19:52:03,676:INFO:Adding model into prep_pipe
2025-06-19 19:52:03,678:WARNING:Only Model saved as it was a pipeline.
2025-06-19 19:52:04,136:INFO:automl_models\pycaret_pycaret_kneighborsclassifier.pkl saved in current working directory
2025-06-19 19:52:04,353:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2025-06-19 19:52:04,354:INFO:save_model() successfully completed......................................
2025-06-19 20:04:42,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:04:42,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:04:42,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:04:42,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:22:34,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:22:34,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:22:34,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:22:34,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:29:44,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:29:44,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:29:44,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:29:44,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:30:23,485:INFO:PyCaret ClassificationExperiment
2025-06-19 20:30:23,485:INFO:Logging name: clf-default-name
2025-06-19 20:30:23,485:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-19 20:30:23,485:INFO:version 3.3.0
2025-06-19 20:30:23,485:INFO:Initializing setup()
2025-06-19 20:30:23,485:INFO:self.USI: 962d
2025-06-19 20:30:23,485:INFO:self._variable_keys: {'gpu_param', 'target_param', 'n_jobs_param', 'seed', '_ml_usecase', 'idx', 'data', 'fold_groups_param', 'y_train', 'USI', 'X', 'X_train', 'html_param', 'y', 'fold_shuffle_param', 'log_plots_param', 'pipeline', 'fold_generator', 'X_test', 'memory', 'exp_name_log', 'gpu_n_jobs_param', 'fix_imbalance', 'is_multiclass', '_available_plots', 'exp_id', 'y_test', 'logging_param'}
2025-06-19 20:30:23,485:INFO:Checking environment
2025-06-19 20:30:23,485:INFO:python_version: 3.10.6
2025-06-19 20:30:23,485:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2025-06-19 20:30:23,485:INFO:machine: AMD64
2025-06-19 20:30:23,507:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-19 20:30:23,515:INFO:Memory: svmem(total=8344559616, available=635465728, percent=92.4, used=7709093888, free=635465728)
2025-06-19 20:30:23,516:INFO:Physical Core: 2
2025-06-19 20:30:23,516:INFO:Logical Core: 4
2025-06-19 20:30:23,516:INFO:Checking libraries
2025-06-19 20:30:23,516:INFO:System:
2025-06-19 20:30:23,516:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2025-06-19 20:30:23,516:INFO:executable: C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\python.exe
2025-06-19 20:30:23,517:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-19 20:30:23,517:INFO:PyCaret required dependencies:
2025-06-19 20:30:23,521:INFO:                 pip: 24.3.1
2025-06-19 20:30:23,521:INFO:          setuptools: 69.5.1
2025-06-19 20:30:23,521:INFO:             pycaret: 3.3.0
2025-06-19 20:30:23,521:INFO:             IPython: 8.15.0
2025-06-19 20:30:23,521:INFO:          ipywidgets: 8.1.1
2025-06-19 20:30:23,521:INFO:                tqdm: 4.67.1
2025-06-19 20:30:23,522:INFO:               numpy: 1.26.4
2025-06-19 20:30:23,522:INFO:              pandas: 2.1.4
2025-06-19 20:30:23,522:INFO:              jinja2: 3.1.2
2025-06-19 20:30:23,522:INFO:               scipy: 1.11.4
2025-06-19 20:30:23,522:INFO:              joblib: 1.3.2
2025-06-19 20:30:23,522:INFO:             sklearn: 1.4.1.post1
2025-06-19 20:30:23,522:INFO:                pyod: 2.0.5
2025-06-19 20:30:23,523:INFO:            imblearn: 0.12.0
2025-06-19 20:30:23,523:INFO:   category_encoders: 2.7.0
2025-06-19 20:30:23,523:INFO:            lightgbm: 4.3.0
2025-06-19 20:30:23,523:INFO:               numba: 0.61.2
2025-06-19 20:30:23,523:INFO:            requests: 2.31.0
2025-06-19 20:30:23,523:INFO:          matplotlib: 3.7.2
2025-06-19 20:30:23,523:INFO:          scikitplot: 0.3.7
2025-06-19 20:30:23,523:INFO:         yellowbrick: 1.5
2025-06-19 20:30:23,523:INFO:              plotly: 5.18.0
2025-06-19 20:30:23,523:INFO:    plotly-resampler: Not installed
2025-06-19 20:30:23,523:INFO:             kaleido: 0.2.1
2025-06-19 20:30:23,523:INFO:           schemdraw: 0.15
2025-06-19 20:30:23,523:INFO:         statsmodels: 0.14.4
2025-06-19 20:30:23,523:INFO:              sktime: 0.26.0
2025-06-19 20:30:23,523:INFO:               tbats: 1.1.3
2025-06-19 20:30:23,523:INFO:            pmdarima: 2.0.4
2025-06-19 20:30:23,523:INFO:              psutil: 5.9.8
2025-06-19 20:30:23,524:INFO:          markupsafe: 2.1.3
2025-06-19 20:30:23,524:INFO:             pickle5: Not installed
2025-06-19 20:30:23,524:INFO:         cloudpickle: 3.0.0
2025-06-19 20:30:23,524:INFO:         deprecation: 2.1.0
2025-06-19 20:30:23,524:INFO:              xxhash: 3.5.0
2025-06-19 20:30:23,524:INFO:           wurlitzer: Not installed
2025-06-19 20:30:23,524:INFO:PyCaret optional dependencies:
2025-06-19 20:30:24,748:INFO:                shap: Not installed
2025-06-19 20:30:24,749:INFO:           interpret: Not installed
2025-06-19 20:30:24,749:INFO:                umap: Not installed
2025-06-19 20:30:24,749:INFO:     ydata_profiling: Not installed
2025-06-19 20:30:24,749:INFO:  explainerdashboard: Not installed
2025-06-19 20:30:24,749:INFO:             autoviz: Not installed
2025-06-19 20:30:24,749:INFO:           fairlearn: Not installed
2025-06-19 20:30:24,749:INFO:          deepchecks: Not installed
2025-06-19 20:30:24,749:INFO:             xgboost: 2.0.3
2025-06-19 20:30:24,750:INFO:            catboost: 1.2.8
2025-06-19 20:30:24,750:INFO:              kmodes: Not installed
2025-06-19 20:30:24,750:INFO:             mlxtend: 0.22.0
2025-06-19 20:30:24,750:INFO:       statsforecast: Not installed
2025-06-19 20:30:24,750:INFO:        tune_sklearn: Not installed
2025-06-19 20:30:24,750:INFO:                 ray: Not installed
2025-06-19 20:30:24,750:INFO:            hyperopt: Not installed
2025-06-19 20:30:24,750:INFO:              optuna: Not installed
2025-06-19 20:30:24,750:INFO:               skopt: Not installed
2025-06-19 20:30:24,750:INFO:              mlflow: 2.22.0
2025-06-19 20:30:24,750:INFO:              gradio: Not installed
2025-06-19 20:30:24,750:INFO:             fastapi: 0.111.0
2025-06-19 20:30:24,750:INFO:             uvicorn: 0.29.0
2025-06-19 20:30:24,750:INFO:              m2cgen: Not installed
2025-06-19 20:30:24,750:INFO:           evidently: Not installed
2025-06-19 20:30:24,750:INFO:               fugue: Not installed
2025-06-19 20:30:24,750:INFO:           streamlit: 1.32.0
2025-06-19 20:30:24,751:INFO:             prophet: Not installed
2025-06-19 20:30:24,751:INFO:None
2025-06-19 20:30:24,751:INFO:Set up data.
2025-06-19 20:30:24,789:INFO:Set up folding strategy.
2025-06-19 20:30:24,789:INFO:Set up train/test split.
2025-06-19 20:30:24,860:INFO:Set up index.
2025-06-19 20:30:24,864:INFO:Assigning column types.
2025-06-19 20:30:24,945:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-19 20:30:24,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-19 20:30:25,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 20:30:25,050:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:25,052:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:25,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-19 20:30:25,315:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 20:30:25,363:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:25,367:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:25,368:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-19 20:30:25,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 20:30:25,505:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:25,513:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:25,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-19 20:30:25,614:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:25,619:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:25,621:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-19 20:30:25,715:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:25,718:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:25,830:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:25,835:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:25,838:INFO:Preparing preprocessing pipeline...
2025-06-19 20:30:25,856:INFO:Set up simple imputation.
2025-06-19 20:30:26,004:INFO:Finished creating preprocessing pipeline.
2025-06-19 20:30:26,011:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Tayyaba\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-19 20:30:26,011:INFO:Creating final display dataframe.
2025-06-19 20:30:26,433:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       is_promoted
2                   Target type            Binary
3           Original data shape       (54808, 54)
4        Transformed data shape       (54808, 54)
5   Transformed train set shape       (43846, 54)
6    Transformed test set shape       (10962, 54)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              962d
2025-06-19 20:30:26,562:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:26,566:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:26,742:INFO:Soft dependency imported: xgboost: 2.0.3
2025-06-19 20:30:26,747:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-19 20:30:26,750:INFO:setup() successfully completed in 3.34s...............
2025-06-19 20:30:26,750:INFO:Initializing compare_models()
2025-06-19 20:30:26,750:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, include=['lr', 'rf', 'et', 'ada', 'gbc', 'lda', 'nb', 'dt', 'svm', 'knn'], fold=None, round=4, cross_validation=True, sort=F1, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, 'include': ['lr', 'rf', 'et', 'ada', 'gbc', 'lda', 'nb', 'dt', 'svm', 'knn'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-19 20:30:26,750:INFO:Checking exceptions
2025-06-19 20:30:26,830:INFO:Preparing display monitor
2025-06-19 20:30:26,833:INFO:Initializing Logistic Regression
2025-06-19 20:30:26,833:INFO:Total runtime is 0.0 minutes
2025-06-19 20:30:26,833:INFO:SubProcess create_model() called ==================================
2025-06-19 20:30:26,833:INFO:Initializing create_model()
2025-06-19 20:30:26,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:30:26,834:INFO:Checking exceptions
2025-06-19 20:30:26,834:INFO:Importing libraries
2025-06-19 20:30:26,834:INFO:Copying training dataset
2025-06-19 20:30:26,944:INFO:Defining folds
2025-06-19 20:30:26,944:INFO:Declaring metric variables
2025-06-19 20:30:26,945:INFO:Importing untrained model
2025-06-19 20:30:26,945:INFO:Logistic Regression Imported successfully
2025-06-19 20:30:26,945:INFO:Starting cross validation
2025-06-19 20:30:26,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:30:55,072:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:30:56,048:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:30:57,700:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:31:09,270:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:31:11,954:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:31:14,362:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:31:21,706:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-19 20:31:21,789:INFO:Calculating mean and std
2025-06-19 20:31:21,790:INFO:Creating metrics dataframe
2025-06-19 20:31:21,796:INFO:Uploading results into container
2025-06-19 20:31:21,797:INFO:Uploading model into container now
2025-06-19 20:31:21,798:INFO:_master_model_container: 1
2025-06-19 20:31:21,798:INFO:_display_container: 2
2025-06-19 20:31:21,799:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-19 20:31:21,799:INFO:create_model() successfully completed......................................
2025-06-19 20:31:22,472:INFO:SubProcess create_model() end ==================================
2025-06-19 20:31:22,473:INFO:Creating metrics dataframe
2025-06-19 20:31:22,486:INFO:Initializing Random Forest Classifier
2025-06-19 20:31:22,487:INFO:Total runtime is 0.9275725245475769 minutes
2025-06-19 20:31:22,488:INFO:SubProcess create_model() called ==================================
2025-06-19 20:31:22,488:INFO:Initializing create_model()
2025-06-19 20:31:22,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:31:22,488:INFO:Checking exceptions
2025-06-19 20:31:22,488:INFO:Importing libraries
2025-06-19 20:31:22,488:INFO:Copying training dataset
2025-06-19 20:31:22,751:INFO:Defining folds
2025-06-19 20:31:22,752:INFO:Declaring metric variables
2025-06-19 20:31:22,752:INFO:Importing untrained model
2025-06-19 20:31:22,753:INFO:Random Forest Classifier Imported successfully
2025-06-19 20:31:22,754:INFO:Starting cross validation
2025-06-19 20:31:22,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:31:59,426:INFO:Calculating mean and std
2025-06-19 20:31:59,427:INFO:Creating metrics dataframe
2025-06-19 20:31:59,431:INFO:Uploading results into container
2025-06-19 20:31:59,433:INFO:Uploading model into container now
2025-06-19 20:31:59,433:INFO:_master_model_container: 2
2025-06-19 20:31:59,434:INFO:_display_container: 2
2025-06-19 20:31:59,434:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-06-19 20:31:59,435:INFO:create_model() successfully completed......................................
2025-06-19 20:31:59,644:INFO:SubProcess create_model() end ==================================
2025-06-19 20:31:59,644:INFO:Creating metrics dataframe
2025-06-19 20:31:59,650:INFO:Initializing Extra Trees Classifier
2025-06-19 20:31:59,650:INFO:Total runtime is 1.5469571272532145 minutes
2025-06-19 20:31:59,651:INFO:SubProcess create_model() called ==================================
2025-06-19 20:31:59,651:INFO:Initializing create_model()
2025-06-19 20:31:59,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:31:59,651:INFO:Checking exceptions
2025-06-19 20:31:59,651:INFO:Importing libraries
2025-06-19 20:31:59,652:INFO:Copying training dataset
2025-06-19 20:31:59,825:INFO:Defining folds
2025-06-19 20:31:59,825:INFO:Declaring metric variables
2025-06-19 20:31:59,826:INFO:Importing untrained model
2025-06-19 20:31:59,827:INFO:Extra Trees Classifier Imported successfully
2025-06-19 20:31:59,827:INFO:Starting cross validation
2025-06-19 20:31:59,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:32:43,380:INFO:Calculating mean and std
2025-06-19 20:32:43,381:INFO:Creating metrics dataframe
2025-06-19 20:32:43,386:INFO:Uploading results into container
2025-06-19 20:32:43,386:INFO:Uploading model into container now
2025-06-19 20:32:43,387:INFO:_master_model_container: 3
2025-06-19 20:32:43,387:INFO:_display_container: 2
2025-06-19 20:32:43,388:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-06-19 20:32:43,388:INFO:create_model() successfully completed......................................
2025-06-19 20:32:43,597:INFO:SubProcess create_model() end ==================================
2025-06-19 20:32:43,597:INFO:Creating metrics dataframe
2025-06-19 20:32:43,602:INFO:Initializing Ada Boost Classifier
2025-06-19 20:32:43,602:INFO:Total runtime is 2.2794896245002745 minutes
2025-06-19 20:32:43,603:INFO:SubProcess create_model() called ==================================
2025-06-19 20:32:43,603:INFO:Initializing create_model()
2025-06-19 20:32:43,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:32:43,603:INFO:Checking exceptions
2025-06-19 20:32:43,603:INFO:Importing libraries
2025-06-19 20:32:43,604:INFO:Copying training dataset
2025-06-19 20:32:43,784:INFO:Defining folds
2025-06-19 20:32:43,784:INFO:Declaring metric variables
2025-06-19 20:32:43,785:INFO:Importing untrained model
2025-06-19 20:32:43,785:INFO:Ada Boost Classifier Imported successfully
2025-06-19 20:32:43,785:INFO:Starting cross validation
2025-06-19 20:32:43,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:32:44,051:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:44,052:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:44,078:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:44,136:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:47,260:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:47,263:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:47,298:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:47,397:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:50,497:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:50,520:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-19 20:32:53,417:INFO:Calculating mean and std
2025-06-19 20:32:53,418:INFO:Creating metrics dataframe
2025-06-19 20:32:53,421:INFO:Uploading results into container
2025-06-19 20:32:53,422:INFO:Uploading model into container now
2025-06-19 20:32:53,423:INFO:_master_model_container: 4
2025-06-19 20:32:53,423:INFO:_display_container: 2
2025-06-19 20:32:53,423:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-06-19 20:32:53,423:INFO:create_model() successfully completed......................................
2025-06-19 20:32:53,643:INFO:SubProcess create_model() end ==================================
2025-06-19 20:32:53,644:INFO:Creating metrics dataframe
2025-06-19 20:32:53,648:INFO:Initializing Gradient Boosting Classifier
2025-06-19 20:32:53,648:INFO:Total runtime is 2.446924591064453 minutes
2025-06-19 20:32:53,655:INFO:SubProcess create_model() called ==================================
2025-06-19 20:32:53,658:INFO:Initializing create_model()
2025-06-19 20:32:53,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:32:53,658:INFO:Checking exceptions
2025-06-19 20:32:53,658:INFO:Importing libraries
2025-06-19 20:32:53,658:INFO:Copying training dataset
2025-06-19 20:32:53,825:INFO:Defining folds
2025-06-19 20:32:53,825:INFO:Declaring metric variables
2025-06-19 20:32:53,825:INFO:Importing untrained model
2025-06-19 20:32:53,826:INFO:Gradient Boosting Classifier Imported successfully
2025-06-19 20:32:53,827:INFO:Starting cross validation
2025-06-19 20:32:53,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:33:32,498:INFO:Calculating mean and std
2025-06-19 20:33:32,500:INFO:Creating metrics dataframe
2025-06-19 20:33:32,504:INFO:Uploading results into container
2025-06-19 20:33:32,505:INFO:Uploading model into container now
2025-06-19 20:33:32,506:INFO:_master_model_container: 5
2025-06-19 20:33:32,506:INFO:_display_container: 2
2025-06-19 20:33:32,508:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-19 20:33:32,508:INFO:create_model() successfully completed......................................
2025-06-19 20:33:32,691:INFO:SubProcess create_model() end ==================================
2025-06-19 20:33:32,691:INFO:Creating metrics dataframe
2025-06-19 20:33:32,698:INFO:Initializing Linear Discriminant Analysis
2025-06-19 20:33:32,698:INFO:Total runtime is 3.0977497140566506 minutes
2025-06-19 20:33:32,698:INFO:SubProcess create_model() called ==================================
2025-06-19 20:33:32,699:INFO:Initializing create_model()
2025-06-19 20:33:32,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:33:32,699:INFO:Checking exceptions
2025-06-19 20:33:32,699:INFO:Importing libraries
2025-06-19 20:33:32,700:INFO:Copying training dataset
2025-06-19 20:33:32,877:INFO:Defining folds
2025-06-19 20:33:32,877:INFO:Declaring metric variables
2025-06-19 20:33:32,878:INFO:Importing untrained model
2025-06-19 20:33:32,878:INFO:Linear Discriminant Analysis Imported successfully
2025-06-19 20:33:32,878:INFO:Starting cross validation
2025-06-19 20:33:32,879:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:33:36,854:INFO:Calculating mean and std
2025-06-19 20:33:36,855:INFO:Creating metrics dataframe
2025-06-19 20:33:36,859:INFO:Uploading results into container
2025-06-19 20:33:36,861:INFO:Uploading model into container now
2025-06-19 20:33:36,862:INFO:_master_model_container: 6
2025-06-19 20:33:36,862:INFO:_display_container: 2
2025-06-19 20:33:36,863:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-19 20:33:36,863:INFO:create_model() successfully completed......................................
2025-06-19 20:33:37,054:INFO:SubProcess create_model() end ==================================
2025-06-19 20:33:37,054:INFO:Creating metrics dataframe
2025-06-19 20:33:37,059:INFO:Initializing Naive Bayes
2025-06-19 20:33:37,060:INFO:Total runtime is 3.1704490860303243 minutes
2025-06-19 20:33:37,060:INFO:SubProcess create_model() called ==================================
2025-06-19 20:33:37,061:INFO:Initializing create_model()
2025-06-19 20:33:37,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:33:37,061:INFO:Checking exceptions
2025-06-19 20:33:37,061:INFO:Importing libraries
2025-06-19 20:33:37,061:INFO:Copying training dataset
2025-06-19 20:33:37,243:INFO:Defining folds
2025-06-19 20:33:37,243:INFO:Declaring metric variables
2025-06-19 20:33:37,243:INFO:Importing untrained model
2025-06-19 20:33:37,244:INFO:Naive Bayes Imported successfully
2025-06-19 20:33:37,245:INFO:Starting cross validation
2025-06-19 20:33:37,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:33:38,261:INFO:Calculating mean and std
2025-06-19 20:33:38,262:INFO:Creating metrics dataframe
2025-06-19 20:33:38,266:INFO:Uploading results into container
2025-06-19 20:33:38,267:INFO:Uploading model into container now
2025-06-19 20:33:38,268:INFO:_master_model_container: 7
2025-06-19 20:33:38,268:INFO:_display_container: 2
2025-06-19 20:33:38,268:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-19 20:33:38,268:INFO:create_model() successfully completed......................................
2025-06-19 20:33:38,426:INFO:SubProcess create_model() end ==================================
2025-06-19 20:33:38,427:INFO:Creating metrics dataframe
2025-06-19 20:33:38,432:INFO:Initializing Decision Tree Classifier
2025-06-19 20:33:38,433:INFO:Total runtime is 3.1933274547259014 minutes
2025-06-19 20:33:38,433:INFO:SubProcess create_model() called ==================================
2025-06-19 20:33:38,433:INFO:Initializing create_model()
2025-06-19 20:33:38,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:33:38,434:INFO:Checking exceptions
2025-06-19 20:33:38,434:INFO:Importing libraries
2025-06-19 20:33:38,434:INFO:Copying training dataset
2025-06-19 20:33:38,601:INFO:Defining folds
2025-06-19 20:33:38,602:INFO:Declaring metric variables
2025-06-19 20:33:38,602:INFO:Importing untrained model
2025-06-19 20:33:38,603:INFO:Decision Tree Classifier Imported successfully
2025-06-19 20:33:38,603:INFO:Starting cross validation
2025-06-19 20:33:38,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:33:41,521:INFO:Calculating mean and std
2025-06-19 20:33:41,522:INFO:Creating metrics dataframe
2025-06-19 20:33:41,525:INFO:Uploading results into container
2025-06-19 20:33:41,526:INFO:Uploading model into container now
2025-06-19 20:33:41,527:INFO:_master_model_container: 8
2025-06-19 20:33:41,527:INFO:_display_container: 2
2025-06-19 20:33:41,527:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-06-19 20:33:41,527:INFO:create_model() successfully completed......................................
2025-06-19 20:33:41,683:INFO:SubProcess create_model() end ==================================
2025-06-19 20:33:41,683:INFO:Creating metrics dataframe
2025-06-19 20:33:41,688:INFO:Initializing SVM - Linear Kernel
2025-06-19 20:33:41,688:INFO:Total runtime is 3.2475780487060546 minutes
2025-06-19 20:33:41,688:INFO:SubProcess create_model() called ==================================
2025-06-19 20:33:41,688:INFO:Initializing create_model()
2025-06-19 20:33:41,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:33:41,689:INFO:Checking exceptions
2025-06-19 20:33:41,689:INFO:Importing libraries
2025-06-19 20:33:41,689:INFO:Copying training dataset
2025-06-19 20:33:41,841:INFO:Defining folds
2025-06-19 20:33:41,841:INFO:Declaring metric variables
2025-06-19 20:33:41,841:INFO:Importing untrained model
2025-06-19 20:33:41,842:INFO:SVM - Linear Kernel Imported successfully
2025-06-19 20:33:41,843:INFO:Starting cross validation
2025-06-19 20:33:41,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:33:48,182:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:48,539:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:49,444:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:50,051:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:52,123:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:52,488:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:52,872:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:56,248:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:56,505:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:58,377:WARNING:C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\Tayyaba\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-06-19 20:33:58,475:INFO:Calculating mean and std
2025-06-19 20:33:58,475:INFO:Creating metrics dataframe
2025-06-19 20:33:58,484:INFO:Uploading results into container
2025-06-19 20:33:58,486:INFO:Uploading model into container now
2025-06-19 20:33:58,486:INFO:_master_model_container: 9
2025-06-19 20:33:58,487:INFO:_display_container: 2
2025-06-19 20:33:58,488:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-19 20:33:58,488:INFO:create_model() successfully completed......................................
2025-06-19 20:33:58,757:INFO:SubProcess create_model() end ==================================
2025-06-19 20:33:58,757:INFO:Creating metrics dataframe
2025-06-19 20:33:58,762:INFO:Initializing K Neighbors Classifier
2025-06-19 20:33:58,763:INFO:Total runtime is 3.532158136367798 minutes
2025-06-19 20:33:58,768:INFO:SubProcess create_model() called ==================================
2025-06-19 20:33:58,769:INFO:Initializing create_model()
2025-06-19 20:33:58,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029290D17940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:33:58,769:INFO:Checking exceptions
2025-06-19 20:33:58,770:INFO:Importing libraries
2025-06-19 20:33:58,770:INFO:Copying training dataset
2025-06-19 20:33:58,993:INFO:Defining folds
2025-06-19 20:33:58,993:INFO:Declaring metric variables
2025-06-19 20:33:58,993:INFO:Importing untrained model
2025-06-19 20:33:58,994:INFO:K Neighbors Classifier Imported successfully
2025-06-19 20:33:58,994:INFO:Starting cross validation
2025-06-19 20:33:58,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-19 20:34:19,347:INFO:Calculating mean and std
2025-06-19 20:34:19,348:INFO:Creating metrics dataframe
2025-06-19 20:34:19,351:INFO:Uploading results into container
2025-06-19 20:34:19,352:INFO:Uploading model into container now
2025-06-19 20:34:19,352:INFO:_master_model_container: 10
2025-06-19 20:34:19,352:INFO:_display_container: 2
2025-06-19 20:34:19,353:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 20:34:19,353:INFO:create_model() successfully completed......................................
2025-06-19 20:34:19,473:INFO:SubProcess create_model() end ==================================
2025-06-19 20:34:19,473:INFO:Creating metrics dataframe
2025-06-19 20:34:19,478:INFO:Initializing create_model()
2025-06-19 20:34:19,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:19,478:INFO:Checking exceptions
2025-06-19 20:34:19,538:INFO:Importing libraries
2025-06-19 20:34:19,538:INFO:Copying training dataset
2025-06-19 20:34:19,681:INFO:Defining folds
2025-06-19 20:34:19,681:INFO:Declaring metric variables
2025-06-19 20:34:19,682:INFO:Importing untrained model
2025-06-19 20:34:19,682:INFO:Declaring custom model
2025-06-19 20:34:19,682:INFO:Linear Discriminant Analysis Imported successfully
2025-06-19 20:34:19,683:INFO:Cross validation set to False
2025-06-19 20:34:19,683:INFO:Fitting Model
2025-06-19 20:34:20,137:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-19 20:34:20,137:INFO:create_model() successfully completed......................................
2025-06-19 20:34:20,274:INFO:Initializing create_model()
2025-06-19 20:34:20,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:20,275:INFO:Checking exceptions
2025-06-19 20:34:20,275:INFO:Importing libraries
2025-06-19 20:34:20,276:INFO:Copying training dataset
2025-06-19 20:34:20,398:INFO:Defining folds
2025-06-19 20:34:20,398:INFO:Declaring metric variables
2025-06-19 20:34:20,399:INFO:Importing untrained model
2025-06-19 20:34:20,399:INFO:Declaring custom model
2025-06-19 20:34:20,401:INFO:Gradient Boosting Classifier Imported successfully
2025-06-19 20:34:20,402:INFO:Cross validation set to False
2025-06-19 20:34:20,402:INFO:Fitting Model
2025-06-19 20:34:27,070:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-19 20:34:27,070:INFO:create_model() successfully completed......................................
2025-06-19 20:34:27,180:INFO:Initializing create_model()
2025-06-19 20:34:27,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:27,180:INFO:Checking exceptions
2025-06-19 20:34:27,181:INFO:Importing libraries
2025-06-19 20:34:27,181:INFO:Copying training dataset
2025-06-19 20:34:27,280:INFO:Defining folds
2025-06-19 20:34:27,281:INFO:Declaring metric variables
2025-06-19 20:34:27,281:INFO:Importing untrained model
2025-06-19 20:34:27,281:INFO:Declaring custom model
2025-06-19 20:34:27,282:INFO:SVM - Linear Kernel Imported successfully
2025-06-19 20:34:27,283:INFO:Cross validation set to False
2025-06-19 20:34:27,283:INFO:Fitting Model
2025-06-19 20:34:29,638:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-19 20:34:29,638:INFO:create_model() successfully completed......................................
2025-06-19 20:34:29,753:INFO:Initializing create_model()
2025-06-19 20:34:29,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:29,753:INFO:Checking exceptions
2025-06-19 20:34:29,753:INFO:Importing libraries
2025-06-19 20:34:29,753:INFO:Copying training dataset
2025-06-19 20:34:29,843:INFO:Defining folds
2025-06-19 20:34:29,843:INFO:Declaring metric variables
2025-06-19 20:34:29,844:INFO:Importing untrained model
2025-06-19 20:34:29,844:INFO:Declaring custom model
2025-06-19 20:34:29,845:INFO:Logistic Regression Imported successfully
2025-06-19 20:34:29,846:INFO:Cross validation set to False
2025-06-19 20:34:29,847:INFO:Fitting Model
2025-06-19 20:34:37,878:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-19 20:34:37,878:INFO:create_model() successfully completed......................................
2025-06-19 20:34:38,071:INFO:Initializing create_model()
2025-06-19 20:34:38,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:38,072:INFO:Checking exceptions
2025-06-19 20:34:38,073:INFO:Importing libraries
2025-06-19 20:34:38,073:INFO:Copying training dataset
2025-06-19 20:34:38,150:INFO:Defining folds
2025-06-19 20:34:38,150:INFO:Declaring metric variables
2025-06-19 20:34:38,150:INFO:Importing untrained model
2025-06-19 20:34:38,150:INFO:Declaring custom model
2025-06-19 20:34:38,151:INFO:Random Forest Classifier Imported successfully
2025-06-19 20:34:38,152:INFO:Cross validation set to False
2025-06-19 20:34:38,152:INFO:Fitting Model
2025-06-19 20:34:41,364:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-06-19 20:34:41,365:INFO:create_model() successfully completed......................................
2025-06-19 20:34:41,488:INFO:Initializing create_model()
2025-06-19 20:34:41,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:41,489:INFO:Checking exceptions
2025-06-19 20:34:41,493:INFO:Importing libraries
2025-06-19 20:34:41,493:INFO:Copying training dataset
2025-06-19 20:34:41,600:INFO:Defining folds
2025-06-19 20:34:41,601:INFO:Declaring metric variables
2025-06-19 20:34:41,601:INFO:Importing untrained model
2025-06-19 20:34:41,601:INFO:Declaring custom model
2025-06-19 20:34:41,601:INFO:Decision Tree Classifier Imported successfully
2025-06-19 20:34:41,602:INFO:Cross validation set to False
2025-06-19 20:34:41,602:INFO:Fitting Model
2025-06-19 20:34:42,000:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-06-19 20:34:42,001:INFO:create_model() successfully completed......................................
2025-06-19 20:34:42,208:INFO:Initializing create_model()
2025-06-19 20:34:42,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:42,208:INFO:Checking exceptions
2025-06-19 20:34:42,210:INFO:Importing libraries
2025-06-19 20:34:42,210:INFO:Copying training dataset
2025-06-19 20:34:42,321:INFO:Defining folds
2025-06-19 20:34:42,322:INFO:Declaring metric variables
2025-06-19 20:34:42,322:INFO:Importing untrained model
2025-06-19 20:34:42,322:INFO:Declaring custom model
2025-06-19 20:34:42,322:INFO:Extra Trees Classifier Imported successfully
2025-06-19 20:34:42,323:INFO:Cross validation set to False
2025-06-19 20:34:42,323:INFO:Fitting Model
2025-06-19 20:34:46,636:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-06-19 20:34:46,637:INFO:create_model() successfully completed......................................
2025-06-19 20:34:46,807:INFO:Initializing create_model()
2025-06-19 20:34:46,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:46,808:INFO:Checking exceptions
2025-06-19 20:34:46,808:INFO:Importing libraries
2025-06-19 20:34:46,809:INFO:Copying training dataset
2025-06-19 20:34:46,913:INFO:Defining folds
2025-06-19 20:34:46,913:INFO:Declaring metric variables
2025-06-19 20:34:46,913:INFO:Importing untrained model
2025-06-19 20:34:46,914:INFO:Declaring custom model
2025-06-19 20:34:46,914:INFO:Ada Boost Classifier Imported successfully
2025-06-19 20:34:46,914:INFO:Cross validation set to False
2025-06-19 20:34:46,914:INFO:Fitting Model
2025-06-19 20:34:48,618:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-06-19 20:34:48,619:INFO:create_model() successfully completed......................................
2025-06-19 20:34:48,755:INFO:Initializing create_model()
2025-06-19 20:34:48,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:48,755:INFO:Checking exceptions
2025-06-19 20:34:48,756:INFO:Importing libraries
2025-06-19 20:34:48,756:INFO:Copying training dataset
2025-06-19 20:34:48,868:INFO:Defining folds
2025-06-19 20:34:48,868:INFO:Declaring metric variables
2025-06-19 20:34:48,869:INFO:Importing untrained model
2025-06-19 20:34:48,869:INFO:Declaring custom model
2025-06-19 20:34:48,870:INFO:K Neighbors Classifier Imported successfully
2025-06-19 20:34:48,871:INFO:Cross validation set to False
2025-06-19 20:34:48,871:INFO:Fitting Model
2025-06-19 20:34:48,942:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-19 20:34:48,942:INFO:create_model() successfully completed......................................
2025-06-19 20:34:49,099:INFO:Initializing create_model()
2025-06-19 20:34:49,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:49,099:INFO:Checking exceptions
2025-06-19 20:34:49,100:INFO:Importing libraries
2025-06-19 20:34:49,100:INFO:Copying training dataset
2025-06-19 20:34:49,226:INFO:Defining folds
2025-06-19 20:34:49,226:INFO:Declaring metric variables
2025-06-19 20:34:49,226:INFO:Importing untrained model
2025-06-19 20:34:49,226:INFO:Declaring custom model
2025-06-19 20:34:49,227:INFO:Naive Bayes Imported successfully
2025-06-19 20:34:49,228:INFO:Cross validation set to False
2025-06-19 20:34:49,228:INFO:Fitting Model
2025-06-19 20:34:49,301:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-19 20:34:49,313:INFO:create_model() successfully completed......................................
2025-06-19 20:34:49,426:INFO:_master_model_container: 10
2025-06-19 20:34:49,426:INFO:_display_container: 2
2025-06-19 20:34:49,429:INFO:[LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-06-19 20:34:49,476:INFO:compare_models() successfully completed......................................
2025-06-19 20:34:49,545:INFO:Initializing finalize_model()
2025-06-19 20:34:49,545:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-19 20:34:49,546:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-19 20:34:49,601:INFO:Initializing create_model()
2025-06-19 20:34:49,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-19 20:34:49,601:INFO:Checking exceptions
2025-06-19 20:34:49,605:INFO:Importing libraries
2025-06-19 20:34:49,605:INFO:Copying training dataset
2025-06-19 20:34:49,611:INFO:Defining folds
2025-06-19 20:34:49,612:INFO:Declaring metric variables
2025-06-19 20:34:49,612:INFO:Importing untrained model
2025-06-19 20:34:49,612:INFO:Declaring custom model
2025-06-19 20:34:49,613:INFO:Linear Discriminant Analysis Imported successfully
2025-06-19 20:34:49,613:INFO:Cross validation set to False
2025-06-19 20:34:49,613:INFO:Fitting Model
2025-06-19 20:34:50,089:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2025-06-19 20:34:50,089:INFO:create_model() successfully completed......................................
2025-06-19 20:34:50,254:INFO:_master_model_container: 10
2025-06-19 20:34:50,255:INFO:_display_container: 2
2025-06-19 20:34:50,271:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2025-06-19 20:34:50,271:INFO:finalize_model() successfully completed......................................
2025-06-19 20:34:50,483:INFO:Initializing predict_model()
2025-06-19 20:34:50,484:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292F45B1D80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['no_of_trainings', 'age',
                                             'previous_year_rating',
                                             'length_of_service', 'awards_won',
                                             'avg_training_score'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002928E3A3E20>)
2025-06-19 20:34:50,484:INFO:Checking exceptions
2025-06-19 20:34:50,484:INFO:Preloading libraries
2025-06-19 20:39:21,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:39:21,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:39:21,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:39:21,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:44:28,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:44:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:44:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:44:28,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:48:39,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:48:39,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:48:39,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:48:39,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:59:33,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:59:33,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:59:33,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 20:59:33,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:06:05,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:06:05,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:06:05,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:06:05,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:08:56,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:08:56,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:08:56,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:08:56,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:16:48,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:16:48,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:16:48,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:16:48,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:36:05,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:36:05,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:36:05,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:36:05,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:45:35,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:45:35,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:45:35,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:45:35,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:51:00,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:51:00,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:51:00,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 21:51:00,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:03:16,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:03:16,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:03:16,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:03:16,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:06:05,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:06:05,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:06:05,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:06:05,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:29:40,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:29:40,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:29:40,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-19 22:29:40,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
